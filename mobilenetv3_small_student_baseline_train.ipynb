{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oNBfSkWzVuj"
      },
      "source": [
        "Import the necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IHO0Np-_couO"
      },
      "outputs": [],
      "source": [
        "# !pip install torchmetrics\n",
        "# !pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qThspA1gy7m5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from utils import Fashion_MNIST_MobileNet\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyQwMDmnziZM"
      },
      "source": [
        "Check that we have PyTorch CUDA version installed and CUDA available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cp4OVwGzf7w",
        "outputId": "8d417c8f-ab16-4fd6-fa96-c23bcc8337b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version is:  2.1.0\n",
            "Is CUDA available -  True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Torch version is: \", torch.__version__) # Should see something like 2.1.0+cu118\n",
        "print(\"Is CUDA available - \", torch.cuda.is_available())\n",
        "# Just as a fail-safe, switch to CPU if CUDA not available, but training will be very slow\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YuDwLN0Iz7vN"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomVerticalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((72.9404/255,), (90.0212/255,))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                  transforms.Normalize((72.9404/255,), (90.0212/255,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgmGX9mg0PW2",
        "outputId": "1b0edd89-5352-462b-986f-4aec90820638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(72.9404)\n",
            "tensor(90.0212)\n",
            "{0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n"
          ]
        }
      ],
      "source": [
        "# Here we load the download the train dataset\n",
        "train_set = FashionMNIST('./data', download=True, train=True, transform=train_transform)\n",
        "print(train_set.data.float().mean())\n",
        "print(train_set.data.float().std())\n",
        "# Here we load the download the test dataset\n",
        "test_set = FashionMNIST('./data', download=True, train=False, transform=test_transform)\n",
        "# Dictionary of the classes in the dataset\n",
        "classes_dict = dict(enumerate(train_set.classes))\n",
        "print(classes_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Ynv9YA0k4c"
      },
      "source": [
        "Using Resnet without pre-trained weights, we do not have to rescale to 224x224 </br>\n",
        "But if we need to use pre-trained weights, might have to change it\n",
        "</br>\n",
        "Here we set the initial transformations, I need to see the accuracy first before deciding to add more data augmentation (eg. rots, flips, crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3AHT-ML4KFD"
      },
      "source": [
        "**Note:** for model evaluation, we randomly split the train dataset into train/val with into a split of 50,000 images and 10,000 images respectively\n",
        "\n",
        "In order to do this, we set a generator object with manual seed for reproducibility, then use the *random_split()* function provided by PyTorch to do the split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jVnAo0dH2MIJ",
        "outputId": "a88f8512-d184-4072-d45c-981e6103c848"
      },
      "outputs": [],
      "source": [
        "# g1 = torch.Generator().manual_seed(42) # For reproducibility\n",
        "# trainset, valset = random_split(full_trainset, [50000, 10000], g1)\n",
        "# print(len(trainset))\n",
        "# print(len(valset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94GWrAlG027H"
      },
      "source": [
        "Load the datasets as well as the loaders for processing batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A46NZR5e4eKQ"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K7vI2tp7fDSH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/youxiang/anaconda3/envs/dl_proj/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params\n",
            "-------------------------------------------------\n",
            "0 | model     | MobileNetV3        | 1.5 M \n",
            "1 | criterion | CrossEntropyLoss   | 0     \n",
            "2 | acc       | MulticlassAccuracy | 0     \n",
            "3 | f1        | MulticlassF1Score  | 0     \n",
            "-------------------------------------------------\n",
            "1.5 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.5 M     Total params\n",
            "6.111     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 10.34it/s]\n",
            "\n",
            "Epoch: 0 - Metrics: \n",
            "Training loss: None, Validation loss:2.3026, Validation accuracy: 0.1067, Validation F1: 0.0326\n",
            "\n",
            "Epoch 0: 100%|██████████| 938/938 [00:13<00:00, 71.50it/s, v_num=0]        \n",
            "\n",
            "Epoch: 0 - Metrics: \n",
            "Training loss: 0.5758934617042542, Validation loss:0.5823, Validation accuracy: 0.7948, Validation F1: 0.7709\n",
            "\n",
            "Epoch 1: 100%|██████████| 938/938 [00:13<00:00, 69.56it/s, v_num=0, val_acc=0.795, val_f1=0.771]\n",
            "\n",
            "Epoch: 1 - Metrics: \n",
            "Training loss: 1.441855788230896, Validation loss:0.5080, Validation accuracy: 0.8168, Validation F1: 0.8160\n",
            "\n",
            "Epoch 2: 100%|██████████| 938/938 [00:13<00:00, 67.51it/s, v_num=0, val_acc=0.817, val_f1=0.816]\n",
            "\n",
            "Epoch: 2 - Metrics: \n",
            "Training loss: 0.24897129833698273, Validation loss:0.4325, Validation accuracy: 0.8449, Validation F1: 0.8440\n",
            "\n",
            "Epoch 3: 100%|██████████| 938/938 [00:14<00:00, 64.67it/s, v_num=0, val_acc=0.845, val_f1=0.844]\n",
            "\n",
            "Epoch: 3 - Metrics: \n",
            "Training loss: 0.4541736841201782, Validation loss:0.4704, Validation accuracy: 0.8272, Validation F1: 0.8186\n",
            "\n",
            "Epoch 4: 100%|██████████| 938/938 [00:14<00:00, 66.41it/s, v_num=0, val_acc=0.827, val_f1=0.819]\n",
            "\n",
            "Epoch: 4 - Metrics: \n",
            "Training loss: 0.4738679826259613, Validation loss:0.4102, Validation accuracy: 0.8517, Validation F1: 0.8486\n",
            "\n",
            "Epoch 5: 100%|██████████| 938/938 [00:14<00:00, 64.64it/s, v_num=0, val_acc=0.852, val_f1=0.849]\n",
            "\n",
            "Epoch: 5 - Metrics: \n",
            "Training loss: 0.28813064098358154, Validation loss:0.4946, Validation accuracy: 0.8242, Validation F1: 0.8209\n",
            "\n",
            "Epoch 6: 100%|██████████| 938/938 [00:14<00:00, 63.66it/s, v_num=0, val_acc=0.824, val_f1=0.821]\n",
            "\n",
            "Epoch: 6 - Metrics: \n",
            "Training loss: 0.40649133920669556, Validation loss:0.3948, Validation accuracy: 0.8589, Validation F1: 0.8565\n",
            "\n",
            "Epoch 7: 100%|██████████| 938/938 [00:14<00:00, 63.60it/s, v_num=0, val_acc=0.859, val_f1=0.856]\n",
            "\n",
            "Epoch: 7 - Metrics: \n",
            "Training loss: 0.2202262580394745, Validation loss:0.3611, Validation accuracy: 0.8702, Validation F1: 0.8693\n",
            "\n",
            "Epoch 8: 100%|██████████| 938/938 [00:13<00:00, 69.38it/s, v_num=0, val_acc=0.870, val_f1=0.869]\n",
            "\n",
            "Epoch: 8 - Metrics: \n",
            "Training loss: 0.3619951009750366, Validation loss:0.4127, Validation accuracy: 0.8429, Validation F1: 0.8434\n",
            "\n",
            "Epoch 9: 100%|██████████| 938/938 [00:13<00:00, 67.27it/s, v_num=0, val_acc=0.843, val_f1=0.843]\n",
            "\n",
            "Epoch: 9 - Metrics: \n",
            "Training loss: 0.7704945802688599, Validation loss:0.4027, Validation accuracy: 0.8495, Validation F1: 0.8446\n",
            "\n",
            "Epoch 10: 100%|██████████| 938/938 [00:14<00:00, 65.94it/s, v_num=0, val_acc=0.850, val_f1=0.845]\n",
            "\n",
            "Epoch: 10 - Metrics: \n",
            "Training loss: 0.29638153314590454, Validation loss:0.5033, Validation accuracy: 0.8360, Validation F1: 0.8321\n",
            "\n",
            "Epoch 11: 100%|██████████| 938/938 [00:14<00:00, 66.53it/s, v_num=0, val_acc=0.836, val_f1=0.832]\n",
            "\n",
            "Epoch: 11 - Metrics: \n",
            "Training loss: 0.5549069046974182, Validation loss:0.3326, Validation accuracy: 0.8772, Validation F1: 0.8760\n",
            "\n",
            "Epoch 12: 100%|██████████| 938/938 [00:13<00:00, 69.31it/s, v_num=0, val_acc=0.877, val_f1=0.876]\n",
            "\n",
            "Epoch: 12 - Metrics: \n",
            "Training loss: 0.3724493682384491, Validation loss:0.3596, Validation accuracy: 0.8670, Validation F1: 0.8678\n",
            "\n",
            "Epoch 13: 100%|██████████| 938/938 [00:13<00:00, 69.89it/s, v_num=0, val_acc=0.867, val_f1=0.868]\n",
            "\n",
            "Epoch: 13 - Metrics: \n",
            "Training loss: 0.11988939344882965, Validation loss:0.3413, Validation accuracy: 0.8735, Validation F1: 0.8737\n",
            "\n",
            "Epoch 14: 100%|██████████| 938/938 [00:14<00:00, 65.71it/s, v_num=0, val_acc=0.873, val_f1=0.874]\n",
            "\n",
            "Epoch: 14 - Metrics: \n",
            "Training loss: 0.3410347104072571, Validation loss:0.3601, Validation accuracy: 0.8683, Validation F1: 0.8689\n",
            "\n",
            "Epoch 15: 100%|██████████| 938/938 [00:13<00:00, 68.13it/s, v_num=0, val_acc=0.868, val_f1=0.869]\n",
            "\n",
            "Epoch: 15 - Metrics: \n",
            "Training loss: 0.3409026861190796, Validation loss:0.3431, Validation accuracy: 0.8770, Validation F1: 0.8735\n",
            "\n",
            "Epoch 16: 100%|██████████| 938/938 [00:13<00:00, 69.79it/s, v_num=0, val_acc=0.877, val_f1=0.874]\n",
            "\n",
            "Epoch: 16 - Metrics: \n",
            "Training loss: 0.18889492750167847, Validation loss:0.3310, Validation accuracy: 0.8829, Validation F1: 0.8812\n",
            "\n",
            "Epoch 17: 100%|██████████| 938/938 [00:13<00:00, 70.10it/s, v_num=0, val_acc=0.883, val_f1=0.881]\n",
            "\n",
            "Epoch: 17 - Metrics: \n",
            "Training loss: 0.23449364304542542, Validation loss:0.3050, Validation accuracy: 0.8905, Validation F1: 0.8900\n",
            "\n",
            "Epoch 18: 100%|██████████| 938/938 [00:13<00:00, 69.38it/s, v_num=0, val_acc=0.891, val_f1=0.890]\n",
            "\n",
            "Epoch: 18 - Metrics: \n",
            "Training loss: 1.014680027961731, Validation loss:0.3082, Validation accuracy: 0.8911, Validation F1: 0.8900\n",
            "\n",
            "Epoch 19: 100%|██████████| 938/938 [00:14<00:00, 66.55it/s, v_num=0, val_acc=0.891, val_f1=0.890]\n",
            "\n",
            "Epoch: 19 - Metrics: \n",
            "Training loss: 0.20624971389770508, Validation loss:0.3154, Validation accuracy: 0.8841, Validation F1: 0.8828\n",
            "\n",
            "Epoch 20: 100%|██████████| 938/938 [00:14<00:00, 64.83it/s, v_num=0, val_acc=0.884, val_f1=0.883]\n",
            "\n",
            "Epoch: 20 - Metrics: \n",
            "Training loss: 0.3267571032047272, Validation loss:0.3301, Validation accuracy: 0.8824, Validation F1: 0.8795\n",
            "\n",
            "Epoch 21: 100%|██████████| 938/938 [00:14<00:00, 65.10it/s, v_num=0, val_acc=0.882, val_f1=0.880]\n",
            "\n",
            "Epoch: 21 - Metrics: \n",
            "Training loss: 0.4302794337272644, Validation loss:0.3074, Validation accuracy: 0.8877, Validation F1: 0.8886\n",
            "\n",
            "Epoch 22: 100%|██████████| 938/938 [00:13<00:00, 68.28it/s, v_num=0, val_acc=0.888, val_f1=0.889]\n",
            "\n",
            "Epoch: 22 - Metrics: \n",
            "Training loss: 0.11751928180456161, Validation loss:0.3369, Validation accuracy: 0.8743, Validation F1: 0.8762\n",
            "\n",
            "Epoch 23: 100%|██████████| 938/938 [00:13<00:00, 67.85it/s, v_num=0, val_acc=0.874, val_f1=0.876]\n",
            "\n",
            "Epoch: 23 - Metrics: \n",
            "Training loss: 0.39622119069099426, Validation loss:0.6233, Validation accuracy: 0.7797, Validation F1: 0.7678\n",
            "\n",
            "Epoch 24: 100%|██████████| 938/938 [00:13<00:00, 69.01it/s, v_num=0, val_acc=0.780, val_f1=0.768]\n",
            "\n",
            "Epoch: 24 - Metrics: \n",
            "Training loss: 0.19693103432655334, Validation loss:0.3028, Validation accuracy: 0.8877, Validation F1: 0.8880\n",
            "\n",
            "Epoch 25: 100%|██████████| 938/938 [00:14<00:00, 63.67it/s, v_num=0, val_acc=0.888, val_f1=0.888]\n",
            "\n",
            "Epoch: 25 - Metrics: \n",
            "Training loss: 0.1713135540485382, Validation loss:0.3080, Validation accuracy: 0.8876, Validation F1: 0.8871\n",
            "\n",
            "Epoch 26: 100%|██████████| 938/938 [00:13<00:00, 67.47it/s, v_num=0, val_acc=0.888, val_f1=0.887]\n",
            "\n",
            "Epoch: 26 - Metrics: \n",
            "Training loss: 0.4649392366409302, Validation loss:0.2908, Validation accuracy: 0.8935, Validation F1: 0.8926\n",
            "\n",
            "Epoch 27: 100%|██████████| 938/938 [00:14<00:00, 66.87it/s, v_num=0, val_acc=0.894, val_f1=0.893]\n",
            "\n",
            "Epoch: 27 - Metrics: \n",
            "Training loss: 0.38010478019714355, Validation loss:0.3008, Validation accuracy: 0.8930, Validation F1: 0.8924\n",
            "\n",
            "Epoch 28: 100%|██████████| 938/938 [00:13<00:00, 68.52it/s, v_num=0, val_acc=0.893, val_f1=0.892]\n",
            "\n",
            "Epoch: 28 - Metrics: \n",
            "Training loss: 0.299341082572937, Validation loss:0.2833, Validation accuracy: 0.8989, Validation F1: 0.8985\n",
            "\n",
            "Epoch 29: 100%|██████████| 938/938 [00:14<00:00, 66.12it/s, v_num=0, val_acc=0.899, val_f1=0.899]\n",
            "\n",
            "Epoch: 29 - Metrics: \n",
            "Training loss: 0.26792147755622864, Validation loss:0.2942, Validation accuracy: 0.8955, Validation F1: 0.8956\n",
            "\n",
            "Epoch 29: 100%|██████████| 938/938 [00:15<00:00, 60.71it/s, v_num=0, val_acc=0.896, val_f1=0.896]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: 100%|██████████| 938/938 [00:15<00:00, 60.71it/s, v_num=0, val_acc=0.896, val_f1=0.896]\n"
          ]
        }
      ],
      "source": [
        "model = Fashion_MNIST_MobileNet()\n",
        "checkpoint_callback = ModelCheckpoint(monitor=\"val_acc\", mode='max', filename='{epoch}-{val_loss:.3f}-{val_acc:.3f}', auto_insert_metric_name=True)\n",
        "trainer = pl.Trainer(accelerator='gpu', max_epochs=30, callbacks=[checkpoint_callback])\n",
        "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mldf9PNd6GGO"
      },
      "source": [
        "Load our model with no pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pElf77P86H5F"
      },
      "outputs": [],
      "source": [
        "# model = resnet50(weights=None, num_classes=10)\n",
        "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhJOsTVr82hS"
      },
      "source": [
        "Define the optimizer, loss function and number of epochs to train for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Yj3hY7ew849G"
      },
      "outputs": [],
      "source": [
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3) # Use default lr, betas and epsilon\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# num_epochs = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqTTFC13dPXz"
      },
      "source": [
        "Add our metrics for determining model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k9cFjjEtb9x2"
      },
      "outputs": [],
      "source": [
        "# f1 = F1Score(task=\"multiclass\", num_classes=10).to(device)\n",
        "# acc = Accuracy(task=\"multiclass\", num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah0iQLchdU5r"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "euPbk36OdUWL"
      },
      "outputs": [],
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     running_loss = 0.0\n",
        "#     for idx, (inputs, labels) in enumerate(train_loader, 0):\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#         # Zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Forward + backward + optimize\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         f1.update(outputs, labels)\n",
        "#         acc.update(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item()\n",
        "#         if idx % 100 == 99:    # Print every 100 mini-batches\n",
        "#             print(f'Epoch {epoch + 1}, Batch {idx + 1}, Loss: {running_loss / 100:.4f}')\n",
        "#             running_loss = 0.0\n",
        "#     epoch_f1 = f1.compute()\n",
        "#     epoch_acc = acc.compute()\n",
        "#     print(f'Epoch {epoch + 1}, Acc: {epoch_acc}, F1-score: {epoch_f1}')\n",
        "\n",
        "# print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

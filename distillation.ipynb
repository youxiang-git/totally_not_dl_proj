{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import Fashion_MNIST_ResNet, Fashion_MNIST_MobileNet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version is:  2.1.0\n",
      "Is CUDA available -  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Torch version is: \", torch.__version__) # Should see something like 2.1.0+cu118\n",
    "print(\"Is CUDA available - \", torch.cuda.is_available())\n",
    "# Just as a fail-safe, switch to CPU if CUDA not available, but training will be very slow\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomVerticalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((72.9404/255,), (90.0212/255,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((72.9404/255,), (90.0212/255,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.9404)\n",
      "tensor(90.0212)\n",
      "{0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}\n"
     ]
    }
   ],
   "source": [
    "# Here we load the download the train dataset\n",
    "train_set = FashionMNIST('./data', download=True, train=True, transform=train_transform)\n",
    "print(train_set.data.float().mean())\n",
    "print(train_set.data.float().std())\n",
    "# Here we load the download the test dataset\n",
    "test_set = FashionMNIST('./data', download=True, train=False, transform=test_transform)\n",
    "# Dictionary of the classes in the dataset\n",
    "classes_dict = dict(enumerate(train_set.classes))\n",
    "print(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = Fashion_MNIST_ResNet.load_from_checkpoint(\"lightning_logs/resnet50/checkpoints/epoch=27-val_loss=0.250-val_acc=0.913.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning Module for Knowledge Distillation\n",
    "class KnowledgeDistillationModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.teacher = teacher_model\n",
    "        self.student = Fashion_MNIST_MobileNet()\n",
    "        self.distillation_temperature = 10.0\n",
    "        self.alpha = 0.0\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.kl_div_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "        self.acc = MulticlassAccuracy(num_classes=10)\n",
    "        self.f1 = MulticlassF1Score(num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        teacher_outputs = self.teacher(images)\n",
    "        student_outputs = self.student(images)\n",
    "\n",
    "        loss = self.distill_loss(student_outputs, teacher_outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def distill_loss(self, student_logits, teacher_logits, labels):\n",
    "        # Calculate the soft targets for the KL Divergence loss\n",
    "        soft_labels = torch.softmax(teacher_logits / self.distillation_temperature, dim=1)\n",
    "        student_log_probs = torch.log_softmax(student_logits / self.distillation_temperature, dim=1)\n",
    "        distillation_loss = self.kl_div_loss(student_log_probs, soft_labels.detach())\n",
    "\n",
    "        # Calculate the student's standard loss\n",
    "        student_loss = self.criterion(student_logits, labels)\n",
    "\n",
    "        # Combine the losses with the distillation alpha weight\n",
    "        loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss * (self.distillation_temperature ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        self.acc.update(outputs, targets)\n",
    "        self.f1.update(outputs, targets)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        e_loss = self.trainer.callback_metrics.get('val_loss')\n",
    "        t_loss = self.trainer.callback_metrics.get('train_loss')\n",
    "        e_acc = self.acc.compute()\n",
    "        e_f1 = self.f1.compute()\n",
    "        self.log(\"val_acc\", e_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_f1\", e_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        print(f\"\\n\\nEpoch: {self.current_epoch} - Metrics: \")\n",
    "        print(f\"Training loss: {t_loss}, Validation loss:{e_loss:.4f}, Validation accuracy: {e_acc:.4f}, Validation F1: {e_f1:.4f}\\n\")\n",
    "        self.acc.reset()\n",
    "        self.f1.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.student.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youxiang/anaconda3/envs/dl_proj/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                    | Params\n",
      "--------------------------------------------------------\n",
      "0 | teacher     | Fashion_MNIST_ResNet    | 23.5 M\n",
      "1 | student     | Fashion_MNIST_MobileNet | 1.5 M \n",
      "2 | criterion   | CrossEntropyLoss        | 0     \n",
      "3 | kl_div_loss | KLDivLoss               | 0     \n",
      "4 | acc         | MulticlassAccuracy      | 0     \n",
      "5 | f1          | MulticlassF1Score       | 0     \n",
      "--------------------------------------------------------\n",
      "25.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.1 M    Total params\n",
      "100.200   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.67it/s]\n",
      "\n",
      "Epoch: 0 - Metrics: \n",
      "Training loss: None, Validation loss:2.3026, Validation accuracy: 0.0634, Validation F1: 0.0420\n",
      "\n",
      "Epoch 0: 100%|██████████| 938/938 [00:19<00:00, 47.76it/s, v_num=0]        \n",
      "\n",
      "Epoch: 0 - Metrics: \n",
      "Training loss: 4.602952480316162, Validation loss:0.7631, Validation accuracy: 0.7870, Validation F1: 0.7798\n",
      "\n",
      "Epoch 1: 100%|██████████| 938/938 [00:19<00:00, 48.44it/s, v_num=0, val_acc=0.787, val_f1=0.780]\n",
      "\n",
      "Epoch: 1 - Metrics: \n",
      "Training loss: 3.7599284648895264, Validation loss:0.6593, Validation accuracy: 0.8139, Validation F1: 0.8084\n",
      "\n",
      "Epoch 2: 100%|██████████| 938/938 [00:19<00:00, 46.93it/s, v_num=0, val_acc=0.814, val_f1=0.808]\n",
      "\n",
      "Epoch: 2 - Metrics: \n",
      "Training loss: 1.469132900238037, Validation loss:0.5319, Validation accuracy: 0.8388, Validation F1: 0.8378\n",
      "\n",
      "Epoch 3: 100%|██████████| 938/938 [00:20<00:00, 46.46it/s, v_num=0, val_acc=0.839, val_f1=0.838]\n",
      "\n",
      "Epoch: 3 - Metrics: \n",
      "Training loss: 1.4297667741775513, Validation loss:0.5411, Validation accuracy: 0.8411, Validation F1: 0.8382\n",
      "\n",
      "Epoch 4: 100%|██████████| 938/938 [00:19<00:00, 47.19it/s, v_num=0, val_acc=0.841, val_f1=0.838]\n",
      "\n",
      "Epoch: 4 - Metrics: \n",
      "Training loss: 3.1553730964660645, Validation loss:0.4570, Validation accuracy: 0.8500, Validation F1: 0.8489\n",
      "\n",
      "Epoch 5: 100%|██████████| 938/938 [00:20<00:00, 46.32it/s, v_num=0, val_acc=0.850, val_f1=0.849]\n",
      "\n",
      "Epoch: 5 - Metrics: \n",
      "Training loss: 1.5576635599136353, Validation loss:0.4580, Validation accuracy: 0.8543, Validation F1: 0.8528\n",
      "\n",
      "Epoch 6: 100%|██████████| 938/938 [00:19<00:00, 46.98it/s, v_num=0, val_acc=0.854, val_f1=0.853]\n",
      "\n",
      "Epoch: 6 - Metrics: \n",
      "Training loss: 2.4854962825775146, Validation loss:0.4273, Validation accuracy: 0.8575, Validation F1: 0.8562\n",
      "\n",
      "Epoch 7: 100%|██████████| 938/938 [00:20<00:00, 45.95it/s, v_num=0, val_acc=0.858, val_f1=0.856]\n",
      "\n",
      "Epoch: 7 - Metrics: \n",
      "Training loss: 6.905879974365234, Validation loss:0.5249, Validation accuracy: 0.8479, Validation F1: 0.8471\n",
      "\n",
      "Epoch 8: 100%|██████████| 938/938 [00:19<00:00, 46.95it/s, v_num=0, val_acc=0.848, val_f1=0.847]\n",
      "\n",
      "Epoch: 8 - Metrics: \n",
      "Training loss: 2.7575812339782715, Validation loss:0.4350, Validation accuracy: 0.8613, Validation F1: 0.8552\n",
      "\n",
      "Epoch 9: 100%|██████████| 938/938 [00:20<00:00, 45.70it/s, v_num=0, val_acc=0.861, val_f1=0.855]\n",
      "\n",
      "Epoch: 9 - Metrics: \n",
      "Training loss: 1.280623197555542, Validation loss:0.4027, Validation accuracy: 0.8654, Validation F1: 0.8654\n",
      "\n",
      "Epoch 10: 100%|██████████| 938/938 [00:20<00:00, 45.90it/s, v_num=0, val_acc=0.865, val_f1=0.865]\n",
      "\n",
      "Epoch: 10 - Metrics: \n",
      "Training loss: 0.7525869607925415, Validation loss:0.4010, Validation accuracy: 0.8695, Validation F1: 0.8684\n",
      "\n",
      "Epoch 11: 100%|██████████| 938/938 [00:19<00:00, 47.18it/s, v_num=0, val_acc=0.869, val_f1=0.868]\n",
      "\n",
      "Epoch: 11 - Metrics: \n",
      "Training loss: 0.8931345343589783, Validation loss:0.4104, Validation accuracy: 0.8685, Validation F1: 0.8650\n",
      "\n",
      "Epoch 12: 100%|██████████| 938/938 [00:20<00:00, 45.10it/s, v_num=0, val_acc=0.868, val_f1=0.865]\n",
      "\n",
      "Epoch: 12 - Metrics: \n",
      "Training loss: 1.4412617683410645, Validation loss:0.3981, Validation accuracy: 0.8690, Validation F1: 0.8676\n",
      "\n",
      "Epoch 13: 100%|██████████| 938/938 [00:19<00:00, 47.72it/s, v_num=0, val_acc=0.869, val_f1=0.868]\n",
      "\n",
      "Epoch: 13 - Metrics: \n",
      "Training loss: 1.0263049602508545, Validation loss:0.3864, Validation accuracy: 0.8723, Validation F1: 0.8699\n",
      "\n",
      "Epoch 14: 100%|██████████| 938/938 [00:19<00:00, 48.36it/s, v_num=0, val_acc=0.872, val_f1=0.870]\n",
      "\n",
      "Epoch: 14 - Metrics: \n",
      "Training loss: 1.4907346963882446, Validation loss:0.3873, Validation accuracy: 0.8723, Validation F1: 0.8711\n",
      "\n",
      "Epoch 15: 100%|██████████| 938/938 [00:19<00:00, 48.95it/s, v_num=0, val_acc=0.872, val_f1=0.871]\n",
      "\n",
      "Epoch: 15 - Metrics: \n",
      "Training loss: 0.9060362577438354, Validation loss:0.3825, Validation accuracy: 0.8741, Validation F1: 0.8728\n",
      "\n",
      "Epoch 16: 100%|██████████| 938/938 [00:20<00:00, 46.77it/s, v_num=0, val_acc=0.874, val_f1=0.873]\n",
      "\n",
      "Epoch: 16 - Metrics: \n",
      "Training loss: 1.022127628326416, Validation loss:0.3870, Validation accuracy: 0.8727, Validation F1: 0.8719\n",
      "\n",
      "Epoch 17: 100%|██████████| 938/938 [00:20<00:00, 45.73it/s, v_num=0, val_acc=0.873, val_f1=0.872]\n",
      "\n",
      "Epoch: 17 - Metrics: \n",
      "Training loss: 1.463563323020935, Validation loss:0.3683, Validation accuracy: 0.8744, Validation F1: 0.8740\n",
      "\n",
      "Epoch 18: 100%|██████████| 938/938 [00:19<00:00, 48.03it/s, v_num=0, val_acc=0.874, val_f1=0.874]\n",
      "\n",
      "Epoch: 18 - Metrics: \n",
      "Training loss: 1.4062385559082031, Validation loss:0.3888, Validation accuracy: 0.8702, Validation F1: 0.8692\n",
      "\n",
      "Epoch 19: 100%|██████████| 938/938 [00:20<00:00, 46.69it/s, v_num=0, val_acc=0.870, val_f1=0.869]\n",
      "\n",
      "Epoch: 19 - Metrics: \n",
      "Training loss: 0.820214033126831, Validation loss:0.3751, Validation accuracy: 0.8756, Validation F1: 0.8751\n",
      "\n",
      "Epoch 20: 100%|██████████| 938/938 [00:20<00:00, 45.49it/s, v_num=0, val_acc=0.876, val_f1=0.875]\n",
      "\n",
      "Epoch: 20 - Metrics: \n",
      "Training loss: 2.8028745651245117, Validation loss:0.3852, Validation accuracy: 0.8741, Validation F1: 0.8733\n",
      "\n",
      "Epoch 21: 100%|██████████| 938/938 [00:20<00:00, 46.48it/s, v_num=0, val_acc=0.874, val_f1=0.873]\n",
      "\n",
      "Epoch: 21 - Metrics: \n",
      "Training loss: 0.7671787738800049, Validation loss:0.3529, Validation accuracy: 0.8822, Validation F1: 0.8804\n",
      "\n",
      "Epoch 22: 100%|██████████| 938/938 [00:20<00:00, 45.47it/s, v_num=0, val_acc=0.882, val_f1=0.880]\n",
      "\n",
      "Epoch: 22 - Metrics: \n",
      "Training loss: 5.848921775817871, Validation loss:0.3493, Validation accuracy: 0.8822, Validation F1: 0.8819\n",
      "\n",
      "Epoch 23: 100%|██████████| 938/938 [00:19<00:00, 47.88it/s, v_num=0, val_acc=0.882, val_f1=0.882]\n",
      "\n",
      "Epoch: 23 - Metrics: \n",
      "Training loss: 0.6575536131858826, Validation loss:0.3611, Validation accuracy: 0.8808, Validation F1: 0.8788\n",
      "\n",
      "Epoch 24: 100%|██████████| 938/938 [00:20<00:00, 46.80it/s, v_num=0, val_acc=0.881, val_f1=0.879]\n",
      "\n",
      "Epoch: 24 - Metrics: \n",
      "Training loss: 0.8390974402427673, Validation loss:0.3528, Validation accuracy: 0.8833, Validation F1: 0.8821\n",
      "\n",
      "Epoch 25: 100%|██████████| 938/938 [00:19<00:00, 47.69it/s, v_num=0, val_acc=0.883, val_f1=0.882]\n",
      "\n",
      "Epoch: 25 - Metrics: \n",
      "Training loss: 3.192613363265991, Validation loss:0.3796, Validation accuracy: 0.8731, Validation F1: 0.8714\n",
      "\n",
      "Epoch 26: 100%|██████████| 938/938 [00:19<00:00, 47.69it/s, v_num=0, val_acc=0.873, val_f1=0.871]\n",
      "\n",
      "Epoch: 26 - Metrics: \n",
      "Training loss: 0.8919667601585388, Validation loss:0.3433, Validation accuracy: 0.8835, Validation F1: 0.8826\n",
      "\n",
      "Epoch 27: 100%|██████████| 938/938 [00:19<00:00, 49.15it/s, v_num=0, val_acc=0.883, val_f1=0.883]\n",
      "\n",
      "Epoch: 27 - Metrics: \n",
      "Training loss: 6.938756465911865, Validation loss:0.3541, Validation accuracy: 0.8793, Validation F1: 0.8782\n",
      "\n",
      "Epoch 28: 100%|██████████| 938/938 [00:18<00:00, 50.21it/s, v_num=0, val_acc=0.879, val_f1=0.878]\n",
      "\n",
      "Epoch: 28 - Metrics: \n",
      "Training loss: 2.170909881591797, Validation loss:0.3314, Validation accuracy: 0.8876, Validation F1: 0.8868\n",
      "\n",
      "Epoch 29: 100%|██████████| 938/938 [00:19<00:00, 49.15it/s, v_num=0, val_acc=0.888, val_f1=0.887]\n",
      "\n",
      "Epoch: 29 - Metrics: \n",
      "Training loss: 0.7327083349227905, Validation loss:0.3545, Validation accuracy: 0.8796, Validation F1: 0.8793\n",
      "\n",
      "Epoch 29: 100%|██████████| 938/938 [00:20<00:00, 46.63it/s, v_num=0, val_acc=0.880, val_f1=0.879]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 938/938 [00:20<00:00, 46.63it/s, v_num=0, val_acc=0.880, val_f1=0.879]\n"
     ]
    }
   ],
   "source": [
    "model = KnowledgeDistillationModule()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_acc\", mode='max', filename='{epoch}-{val_loss:.3f}-{val_acc:.3f}', auto_insert_metric_name=True)\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=30, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
